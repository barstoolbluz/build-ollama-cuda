{
  "lockfile-version": 1,
  "manifest": {
    "version": 1,
    "install": {
      "ollama-cuda": {
        "pkg-path": "flox-cuda/ollama"
      }
    },
    "vars": {
      "OLLAMA_HOST": "0.0.0.0",
      "OLLAMA_PORT": "11434"
    },
    "options": {
      "systems": [
        "aarch64-linux",
        "x86_64-linux"
      ]
    }
  },
  "packages": [
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/rdzv8c1h1x8jg3apjhyil3s23ndpahnf-ollama-0.13.5.drv",
      "description": "Get up and running with large language models locally, using CUDA for NVIDIA GPU acceleration",
      "install_id": "ollama-cuda",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=3e2499d5539c16d0d173ba53552a4ff8547f4539",
      "name": "ollama-0.13.5",
      "pname": "ollama-cuda",
      "rev": "3e2499d5539c16d0d173ba53552a4ff8547f4539",
      "rev_count": 916364,
      "rev_date": "2025-12-25T08:32:45Z",
      "scrape_date": "2025-12-30T11:33:58.101489128Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "ollama-0.13.5",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/azfp9jlx10j8hj1s9wd6ypb7cji3qdd9-ollama-0.13.5"
      },
      "system": "aarch64-linux",
      "group": "toplevel",
      "priority": 5
    },
    {
      "attr_path": "ollama",
      "broken": false,
      "derivation": "/nix/store/zf04iyd0b96gxdcri8lh7y0v3n4r27zz-ollama-0.13.5.drv",
      "description": "Get up and running with large language models locally, using CUDA for NVIDIA GPU acceleration",
      "install_id": "ollama-cuda",
      "license": "MIT",
      "locked_url": "https://github.com/flox/nixpkgs?rev=3e2499d5539c16d0d173ba53552a4ff8547f4539",
      "name": "ollama-0.13.5",
      "pname": "ollama-cuda",
      "rev": "3e2499d5539c16d0d173ba53552a4ff8547f4539",
      "rev_count": 916364,
      "rev_date": "2025-12-25T08:32:45Z",
      "scrape_date": "2025-12-30T11:33:58.101494356Z",
      "stabilities": [
        "staging",
        "unstable"
      ],
      "unfree": false,
      "version": "ollama-0.13.5",
      "outputs_to_install": [
        "out"
      ],
      "outputs": {
        "out": "/nix/store/hmp9x76a3s0n0zxfcd64fpzz98lhdyvk-ollama-0.13.5"
      },
      "system": "x86_64-linux",
      "group": "toplevel",
      "priority": 5
    }
  ]
}
